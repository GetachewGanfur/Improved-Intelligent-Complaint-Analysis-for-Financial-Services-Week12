{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 4: Interactive Chat Interface\n",
    "\n",
    "This notebook demonstrates the creation of an interactive chat interface for the Financial Complaint Analysis RAG system using both Gradio and Streamlit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Working directory: d:\\Coding\\10Academy\\Intelligent-Complaint-Analysis-for-Financial-Services-Week6\\notebooks\n",
      "üìÅ Parent directory: d:\\Coding\\10Academy\\Intelligent-Complaint-Analysis-for-Financial-Services-Week6\n",
      "‚úÖ Vector store exists: True\n",
      "‚úÖ Source directory exists: True\n",
      "üìÅ Python files in src/: ['chat_interface.py', 'config_manager.py', 'eda_preprocessing.py', 'embedding_indexer.py', 'main.py', 'rag_evaluator.py', 'rag_pipeline.py', 'streamlit_app.py', 'system_monitor.py', 'ui_app.py', 'ui_components.py', 'vector_store_utils.py', '__init__.py']\n"
     ]
    }
   ],
   "source": [
    "# Setup paths and imports\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path for imports\n",
    "parent_dir = Path().absolute().parent\n",
    "sys.path.append(str(parent_dir / 'src'))\n",
    "\n",
    "print(f\"üìÅ Working directory: {os.getcwd()}\")\n",
    "print(f\"üìÅ Parent directory: {parent_dir}\")\n",
    "\n",
    "# Check system components\n",
    "vector_store_path = parent_dir / 'vector_store'\n",
    "src_path = parent_dir / 'src'\n",
    "\n",
    "print(f\"‚úÖ Vector store exists: {vector_store_path.exists()}\")\n",
    "print(f\"‚úÖ Source directory exists: {src_path.exists()}\")\n",
    "\n",
    "if src_path.exists():\n",
    "    src_files = [f.name for f in src_path.glob('*.py')]\n",
    "    print(f\"üìÅ Python files in src/: {src_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Gradio imported successfully\n",
      "‚úÖ Streamlit imported successfully\n",
      "‚úÖ Core libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import time\n",
    "import json\n",
    "import logging\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "\n",
    "try:\n",
    "    import gradio as gr\n",
    "    print(\"‚úÖ Gradio imported successfully\")\n",
    "except ImportError:\n",
    "    print(\"‚ùå Gradio not available. Install with: pip install gradio\")\n",
    "    gr = None\n",
    "\n",
    "try:\n",
    "    import streamlit as st\n",
    "    print(\"‚úÖ Streamlit imported successfully\")\n",
    "except ImportError:\n",
    "    print(\"‚ùå Streamlit not available. Install with: pip install streamlit\")\n",
    "    st = None\n",
    "\n",
    "import pandas as pd\n",
    "print(\"‚úÖ Core libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load RAG System Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ RAG system components imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import our RAG system components\n",
    "try:\n",
    "    from rag_pipeline import create_simple_pipeline, RAGPipeline\n",
    "    from chat_interface import ChatInterface, GradioApp, create_chat_app\n",
    "    from vector_store_utils import ComplaintVectorStore\n",
    "    print(\"‚úÖ RAG system components imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Error importing RAG components: {e}\")\n",
    "    print(\"Make sure you've run the previous notebooks to create the necessary files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Initializing RAG pipeline with vector store: d:\\Coding\\10Academy\\Intelligent-Complaint-Analysis-for-Financial-Services-Week6\\vector_store\n",
      "Loading vector store components...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n",
      "INFO:rag_pipeline:RAG Pipeline initialized successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store loaded successfully!\n",
      "- 930430 chunks\n",
      "- 930430 vectors in index\n",
      "- Embedding model: sentence-transformers/all-MiniLM-L6-v2\n",
      "‚úÖ RAG pipeline initialized successfully\n",
      "üß™ Testing with query: What are common credit card issues?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.56it/s]\n",
      "ERROR:rag_pipeline:Error during retrieval: 'chunk_id'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Test successful!\n",
      "   Answer length: 65 characters\n",
      "   Sources retrieved: 0\n",
      "   Confidence: 0.000\n",
      "   Processing time: 0.93s\n"
     ]
    }
   ],
   "source": [
    "# Initialize the RAG pipeline\n",
    "try:\n",
    "    vector_store_dir = str(parent_dir / 'vector_store')\n",
    "    print(f\"üîß Initializing RAG pipeline with vector store: {vector_store_dir}\")\n",
    "    \n",
    "    # Create the pipeline\n",
    "    rag_pipeline = create_simple_pipeline(vector_store_dir)\n",
    "    print(\"‚úÖ RAG pipeline initialized successfully\")\n",
    "    \n",
    "    # Test the pipeline\n",
    "    test_query = \"What are common credit card issues?\"\n",
    "    print(f\"üß™ Testing with query: {test_query}\")\n",
    "    \n",
    "    response = rag_pipeline.run(test_query)\n",
    "    print(f\"‚úÖ Test successful!\")\n",
    "    print(f\"   Answer length: {len(response.answer)} characters\")\n",
    "    print(f\"   Sources retrieved: {len(response.retrieved_sources)}\")\n",
    "    print(f\"   Confidence: {response.confidence_score:.3f}\")\n",
    "    print(f\"   Processing time: {response.processing_time:.2f}s\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error initializing RAG pipeline: {e}\")\n",
    "    print(\"Make sure you've run Task 2 to create the vector store\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Demo: Simple Chat Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_chat_demo():\n",
    "    \"\"\"Simple command-line chat demo\"\"\"\n",
    "    print(\"\\nüè¶ CrediTrust Complaint Analysis Assistant\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Ask questions about financial complaints. Type 'quit' to exit.\\n\")\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            query = input(\"‚ùì Your question: \").strip()\n",
    "            \n",
    "            if query.lower() in ['quit', 'exit', 'q']:\n",
    "                print(\"üëã Goodbye!\")\n",
    "                break\n",
    "            \n",
    "            if not query:\n",
    "                continue\n",
    "            \n",
    "            print(\"\\nü§î Thinking...\")\n",
    "            response = rag_pipeline.run(query)\n",
    "            \n",
    "            print(f\"\\nüí° **Answer:**\")\n",
    "            print(response.answer)\n",
    "            \n",
    "            print(f\"\\nüìä **Confidence:** {response.confidence_score:.1%}\")\n",
    "            print(f\"‚è±Ô∏è  **Processing time:** {response.processing_time:.2f}s\")\n",
    "            \n",
    "            if response.retrieved_sources:\n",
    "                print(f\"\\nüìö **Sources ({len(response.retrieved_sources)}):**\")\n",
    "                for i, source in enumerate(response.retrieved_sources[:3], 1):\n",
    "                    meta = source.metadata\n",
    "                    print(f\"   {i}. Product: {meta.get('product', 'Unknown')} | \"\n",
    "                          f\"Category: {meta.get('category', 'Unknown')} | \"\n",
    "                          f\"Score: {source.score:.3f}\")\n",
    "                    print(f\"      Text: {source.text[:100]}...\")\n",
    "            \n",
    "            print(\"\\n\" + \"-\" * 50)\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n\\nüëã Goodbye!\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ùå Error: {e}\")\n",
    "\n",
    "# Uncomment to run the demo\n",
    "# simple_chat_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Creating Gradio interface...\n",
      "‚úÖ Gradio app created successfully!\n",
      "\n",
      "üìù To launch the interface, run:\n",
      "   chat_app.launch()\n",
      "\n",
      "üåê Or run the standalone app:\n",
      "   python ../src/chat_interface.py\n"
     ]
    }
   ],
   "source": [
    "# Create and launch Gradio interface\n",
    "if gr is not None:\n",
    "    try:\n",
    "        print(\"üöÄ Creating Gradio interface...\")\n",
    "        \n",
    "        # Create the chat app\n",
    "        chat_app = create_chat_app(\n",
    "            vector_store_dir=vector_store_dir,\n",
    "            enable_streaming=False,\n",
    "            share=False\n",
    "        )\n",
    "        \n",
    "        print(\"‚úÖ Gradio app created successfully!\")\n",
    "        print(\"\\nüìù To launch the interface, run:\")\n",
    "        print(\"   chat_app.launch()\")\n",
    "        print(\"\\nüåê Or run the standalone app:\")\n",
    "        print(\"   python ../src/chat_interface.py\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error creating Gradio interface: {e}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Gradio not available. Install with: pip install gradio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch Gradio interface (uncomment to run)\n",
    "# if 'chat_app' in locals():\n",
    "#     print(\"üöÄ Launching Gradio interface...\")\n",
    "#     chat_app.launch(\n",
    "#         share=False,\n",
    "#         server_port=7860,\n",
    "#         show_error=True\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Streamlit Interface Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Streamlit app code:\n",
      "\n",
      "import streamlit as st\n",
      "import sys\n",
      "from pathlib import Path\n",
      "\n",
      "# Add src to path\n",
      "sys.path.append(str(Path(__file__).parent))\n",
      "\n",
      "from rag_pipeline import create_simple_pipeline\n",
      "from chat_interface import ChatInterface\n",
      "\n",
      "# Initialize session state\n",
      "if \"rag_pipeline\" not in st.session_state:\n",
      "    st.session_state.rag_pipeline = create_simple_pipeline(\"../vector_store\")\n",
      "    st.session_state.chat_interface = ChatInterface(st.session_state.rag_pipeline)\n",
      "\n",
      "if \"messages\" not in st.session_state:\n",
      "    st.session_state.messages = []\n",
      "\n",
      "# App header\n",
      "st.title(\"üè¶ CrediTrust Complaint Analysis Assistant\")\n",
      "st.markdown(\"Ask questions about financial complaints and get AI-powered insights.\")\n",
      "\n",
      "# Display chat messages\n",
      "for message in st.session_state.messages:\n",
      "    with st.chat_message(message[\"role\"]):\n",
      "        st.markdown(message[\"content\"])\n",
      "\n",
      "# Chat input\n",
      "if prompt := st.chat_input(\"Ask about financial complaints...\"):\n",
      "    # Add user message\n",
      "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
      "    with st.chat_message(\"user\"):\n",
      "        st.markdown(prompt)\n",
      "\n",
      "    # Get AI response\n",
      "    with st.chat_message(\"assistant\"):\n",
      "        with st.spinner(\"Thinking...\"):\n",
      "            response = st.session_state.rag_pipeline.run(prompt)\n",
      "            st.markdown(response.answer)\n",
      "\n",
      "            # Show sources\n",
      "            if response.retrieved_sources:\n",
      "                with st.expander(f\"üìö Sources ({len(response.retrieved_sources)})\"):\n",
      "                    for i, source in enumerate(response.retrieved_sources, 1):\n",
      "                        st.markdown(f\"**Source {i}** (Score: {source.score:.3f})\")\n",
      "                        meta = source.metadata\n",
      "                        st.markdown(f\"Product: {meta.get('product', 'Unknown')} | \"\n",
      "                                  f\"Category: {meta.get('category', 'Unknown')}\")\n",
      "                        st.markdown(f\"> {source.text[:200]}...\")\n",
      "                        st.markdown(\"---\")\n",
      "\n",
      "    # Add assistant message\n",
      "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": response.answer})\n",
      "\n",
      "# Sidebar\n",
      "with st.sidebar:\n",
      "    st.header(\"üí° Tips\")\n",
      "    st.markdown(\"\"\"\n",
      "    - Be specific in your questions\n",
      "    - Ask about products, issues, or trends\n",
      "    - Check the sources for verification\n",
      "    \"\"\")\n",
      "\n",
      "    if st.button(\"Clear Chat\"):\n",
      "        st.session_state.messages = []\n",
      "        st.rerun()\n",
      "\n",
      "\n",
      "üöÄ To run the Streamlit app:\n",
      "   streamlit run ../src/streamlit_app.py\n"
     ]
    }
   ],
   "source": [
    "# Display Streamlit app code\n",
    "streamlit_app_code = '''\n",
    "import streamlit as st\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append(str(Path(__file__).parent))\n",
    "\n",
    "from rag_pipeline import create_simple_pipeline\n",
    "from chat_interface import ChatInterface\n",
    "\n",
    "# Initialize session state\n",
    "if \"rag_pipeline\" not in st.session_state:\n",
    "    st.session_state.rag_pipeline = create_simple_pipeline(\"../vector_store\")\n",
    "    st.session_state.chat_interface = ChatInterface(st.session_state.rag_pipeline)\n",
    "\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "\n",
    "# App header\n",
    "st.title(\"üè¶ CrediTrust Complaint Analysis Assistant\")\n",
    "st.markdown(\"Ask questions about financial complaints and get AI-powered insights.\")\n",
    "\n",
    "# Display chat messages\n",
    "for message in st.session_state.messages:\n",
    "    with st.chat_message(message[\"role\"]):\n",
    "        st.markdown(message[\"content\"])\n",
    "\n",
    "# Chat input\n",
    "if prompt := st.chat_input(\"Ask about financial complaints...\"):\n",
    "    # Add user message\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.markdown(prompt)\n",
    "    \n",
    "    # Get AI response\n",
    "    with st.chat_message(\"assistant\"):\n",
    "        with st.spinner(\"Thinking...\"):\n",
    "            response = st.session_state.rag_pipeline.run(prompt)\n",
    "            st.markdown(response.answer)\n",
    "            \n",
    "            # Show sources\n",
    "            if response.retrieved_sources:\n",
    "                with st.expander(f\"üìö Sources ({len(response.retrieved_sources)})\"):\n",
    "                    for i, source in enumerate(response.retrieved_sources, 1):\n",
    "                        st.markdown(f\"**Source {i}** (Score: {source.score:.3f})\")\n",
    "                        meta = source.metadata\n",
    "                        st.markdown(f\"Product: {meta.get('product', 'Unknown')} | \"\n",
    "                                  f\"Category: {meta.get('category', 'Unknown')}\")\n",
    "                        st.markdown(f\"> {source.text[:200]}...\")\n",
    "                        st.markdown(\"---\")\n",
    "    \n",
    "    # Add assistant message\n",
    "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": response.answer})\n",
    "\n",
    "# Sidebar\n",
    "with st.sidebar:\n",
    "    st.header(\"üí° Tips\")\n",
    "    st.markdown(\"\"\"\n",
    "    - Be specific in your questions\n",
    "    - Ask about products, issues, or trends\n",
    "    - Check the sources for verification\n",
    "    \"\"\")\n",
    "    \n",
    "    if st.button(\"Clear Chat\"):\n",
    "        st.session_state.messages = []\n",
    "        st.rerun()\n",
    "'''\n",
    "\n",
    "print(\"üìù Streamlit app code:\")\n",
    "print(streamlit_app_code)\n",
    "\n",
    "print(\"\\nüöÄ To run the Streamlit app:\")\n",
    "print(\"   streamlit run ../src/streamlit_app.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing the RAG system with various queries...\n",
      "============================================================\n",
      "\n",
      "1. Query: What are the most common credit card issues?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 15.21it/s]\n",
      "ERROR:rag_pipeline:Error during retrieval: 'chunk_id'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Success!\n",
      "   üìä Confidence: 0.0%\n",
      "   üìö Sources: 0\n",
      "   ‚è±Ô∏è  Time: 0.56s\n",
      "   üìù Answer length: 65 chars\n",
      "   üí° Preview: I couldn't find any relevant information to answer your question....\n",
      "\n",
      "2. Query: Show me complaints about unauthorized charges\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 34.66it/s]\n",
      "ERROR:rag_pipeline:Error during retrieval: 'chunk_id'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Success!\n",
      "   üìä Confidence: 0.0%\n",
      "   üìö Sources: 0\n",
      "   ‚è±Ô∏è  Time: 0.33s\n",
      "   üìù Answer length: 65 chars\n",
      "   üí° Preview: I couldn't find any relevant information to answer your question....\n",
      "\n",
      "3. Query: What billing problems do customers face?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 19.18it/s]\n",
      "ERROR:rag_pipeline:Error during retrieval: 'chunk_id'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Success!\n",
      "   üìä Confidence: 0.0%\n",
      "   üìö Sources: 0\n",
      "   ‚è±Ô∏è  Time: 0.40s\n",
      "   üìù Answer length: 65 chars\n",
      "   üí° Preview: I couldn't find any relevant information to answer your question....\n",
      "\n",
      "4. Query: Tell me about mortgage-related complaints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 43.40it/s]\n",
      "ERROR:rag_pipeline:Error during retrieval: 'chunk_id'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Success!\n",
      "   üìä Confidence: 0.0%\n",
      "   üìö Sources: 0\n",
      "   ‚è±Ô∏è  Time: 0.30s\n",
      "   üìù Answer length: 65 chars\n",
      "   üí° Preview: I couldn't find any relevant information to answer your question....\n",
      "\n",
      "5. Query: What are common debt collection issues?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 19.03it/s]\n",
      "ERROR:rag_pipeline:Error during retrieval: 'chunk_id'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ Success!\n",
      "   üìä Confidence: 0.0%\n",
      "   üìö Sources: 0\n",
      "   ‚è±Ô∏è  Time: 0.36s\n",
      "   üìù Answer length: 65 chars\n",
      "   üí° Preview: I couldn't find any relevant information to answer your question....\n",
      "\n",
      "‚úÖ Testing completed!\n"
     ]
    }
   ],
   "source": [
    "# Test various queries to validate the system\n",
    "test_queries = [\n",
    "    \"What are the most common credit card issues?\",\n",
    "    \"Show me complaints about unauthorized charges\",\n",
    "    \"What billing problems do customers face?\",\n",
    "    \"Tell me about mortgage-related complaints\",\n",
    "    \"What are common debt collection issues?\"\n",
    "]\n",
    "\n",
    "print(\"üß™ Testing the RAG system with various queries...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    try:\n",
    "        print(f\"\\n{i}. Query: {query}\")\n",
    "        response = rag_pipeline.run(query)\n",
    "        \n",
    "        print(f\"   ‚úÖ Success!\")\n",
    "        print(f\"   üìä Confidence: {response.confidence_score:.1%}\")\n",
    "        print(f\"   üìö Sources: {len(response.retrieved_sources)}\")\n",
    "        print(f\"   ‚è±Ô∏è  Time: {response.processing_time:.2f}s\")\n",
    "        print(f\"   üìù Answer length: {len(response.answer)} chars\")\n",
    "        \n",
    "        # Show first few words of answer\n",
    "        answer_preview = ' '.join(response.answer.split()[:15])\n",
    "        print(f\"   üí° Preview: {answer_preview}...\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error: {e}\")\n",
    "\n",
    "print(\"\\n‚úÖ Testing completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Summary and Next Steps\n",
    "\n",
    "##### What We've Built:\n",
    "\n",
    "1. **Modular Chat Interface**: Object-oriented design with separate components for:\n",
    "   - Chat session management\n",
    "   - Response formatting\n",
    "   - Streaming support\n",
    "   - Interface controllers\n",
    "\n",
    "2. **Gradio Web Interface**: Professional chat interface with:\n",
    "   - Real-time conversation\n",
    "   - Source display and verification\n",
    "   - Confidence indicators\n",
    "   - Session management\n",
    "   - Export functionality\n",
    "\n",
    "3. **Streamlit Alternative**: Clean, modern interface with:\n",
    "   - Native chat components\n",
    "   - Expandable source sections\n",
    "   - Sidebar controls\n",
    "   - Session state management\n",
    "\n",
    "##### Key Features Implemented:\n",
    "\n",
    "‚úÖ **Text input box** for user questions\n",
    "‚úÖ **Submit/Ask button** for query processing\n",
    "‚úÖ **Display area** for AI-generated answers\n",
    "‚úÖ **Source display** with metadata and similarity scores\n",
    "‚úÖ **Clear button** to reset conversations\n",
    "‚úÖ **Confidence indicators** for answer reliability\n",
    "‚úÖ **Processing time** display\n",
    "‚úÖ **Error handling** and user feedback\n",
    "‚úÖ **Modular architecture** for easy maintenance\n",
    "\n",
    "##### How to Run:\n",
    "\n",
    "1. **Gradio Interface**:\n",
    "   ```bash\n",
    "   python src/chat_interface.py\n",
    "   ```\n",
    "\n",
    "2. **Streamlit Interface**:\n",
    "   ```bash\n",
    "   streamlit run src/streamlit_app.py\n",
    "   ```\n",
    "\n",
    "3. **Main Application Launcher**:\n",
    "   ```bash\n",
    "   python app.py web\n",
    "   ```\n",
    "\n",
    "##### Files Created:\n",
    "\n",
    "- `src/chat_interface.py` - Main Gradio interface with modular components\n",
    "- `src/streamlit_app.py` - Streamlit alternative interface\n",
    "- `src/ui_components.py` - Reusable UI components\n",
    "- `app.py` - Updated main launcher with web interface support\n",
    "\n",
    "The interfaces provide a user-friendly way for non-technical users to interact with the RAG system while maintaining transparency through source display and confidence indicators."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
